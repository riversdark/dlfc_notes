[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "dlfc_notes",
    "section": "",
    "text": "Preface\nThis project is a WIP.\nI’m a great fan of Bishop’s 2006 book, Pattern Recognition and Machine Learning (PRML), so as an AI practioner coming from a Bayesian background, I’m very much pleasantly surprised to learn that Bishop (and Bishop) have published a new book dedicated to deep learning and artificial intelligence. The focuse on generative models is especially enticing, firstly because it is all the rage for the moment; secondly for a Bayesian statistician, doing generative modeling has always being what we are trained for.\nThe book has 20 chapters, I have divided them roughly into three parts.\n\nFoundations: chapters 1-5, covers the basics of machine learning.\nDeep Learning: chapters 6-13, covers the nuts and bolts of deep learning.\nGenerative Models: chapters 14-20, covers the generative modeling models and techniques.\n\nHerein collected are my notes on the book, and the code to implement the examples in the book. Since these are my understanding of the book, they might not be completely accurate, so please refer to the book for the authoritative source. And if you find any errors, do let me know!\nThe notes and code are written in a literate programming style (See Knuth (1984) for additional discussion). The references are not complete; I only included the ones I have read.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "01.html",
    "href": "01.html",
    "title": "1  the deep learning revolution (3)",
    "section": "",
    "text": "Machine learning (ML) today is one of the most important, and fastest growing, fields of technology. Applications of machine learning are becoming ubiquitous, and solutions learned from data are increasingly displacing traditional hand-crafted algorithms. This has not only led to improved performance for existing technologies but has opened the door to a vast range of new capabilities that would be inconceivable if new algorithms had to be designed explicitly by hand.\nOne particular branch of machine learning, known as deep learning (DL), has emerged as an exceptionally powerful and general-purpose framework for learning from data. Deep learning is based on computational models called neural networks which were originally inspired by mechanisms of learning and information processing in the human brain.\nThe field of artificial intelligence (AI), seeks to recreate the powerful capabilities of the brain in machines, using machine learning methods. Many of the AI systems in current use represent applications of machine learning which are designed to solve very specific and focused problems, and while these are extremely useful they fall far short of the tremendous breadth of capabilities of the human brain. This has led to the introduction of the term artificial general intelligence (AGI), to describe the aspiration of building machines with this much greater flexibility. After many decades of steady progress, machine learning has now entered a phase of very rapid development. Recently, massive deep learning systems called large language models (LLMs) have started to exhibit remarkable capabilities that have been described as the first indications of artificial general intelligence.\nWill LLMs help us achieve the leap from AI to AGI? This is a question hotly debated everyday everwhere; only time will tell.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>the deep learning revolution (3)</span>"
    ]
  }
]