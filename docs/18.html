<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>dlfc_notes – 3&nbsp; Normalizing Flows</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./20.html" rel="next">
<link href="./07.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./18.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Normalizing Flows</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">dlfc_notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Deep Learning Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Normalizing Flows</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Diffusion Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#coupling-flows" id="toc-coupling-flows" class="nav-link active" data-scroll-target="#coupling-flows"><span class="header-section-number">3.1</span> coupling flows</a></li>
  <li><a href="#autoregressive-flows" id="toc-autoregressive-flows" class="nav-link" data-scroll-target="#autoregressive-flows"><span class="header-section-number">3.2</span> autoregressive flows</a></li>
  <li><a href="#continuous-flows" id="toc-continuous-flows" class="nav-link" data-scroll-target="#continuous-flows"><span class="header-section-number">3.3</span> continuous flows</a>
  <ul class="collapse">
  <li><a href="#neural-differential-equation" id="toc-neural-differential-equation" class="nav-link" data-scroll-target="#neural-differential-equation"><span class="header-section-number">3.3.1</span> neural differential equation</a></li>
  <li><a href="#neural-ode-backpropagation" id="toc-neural-ode-backpropagation" class="nav-link" data-scroll-target="#neural-ode-backpropagation"><span class="header-section-number">3.3.2</span> neural ODE backpropagation</a></li>
  <li><a href="#neural-ode-flows" id="toc-neural-ode-flows" class="nav-link" data-scroll-target="#neural-ode-flows"><span class="header-section-number">3.3.3</span> neural ODE flows</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Normalizing Flows</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>GANs</strong> are the first major generative modeling architecture we considered, but nowadays it’s no longer widely used. Although the sampling is easy, it usually has no data likelihood, and the training process is often unstable. <strong>Normalizing flows</strong>, on the contrary, have exact likelihoods we can train on, and the sampling process is also easy (albeit much slower). The exact likelihood is guaranteed by applying some specific constraints on the network architecture (invertibility), which makes the Jacobian determinant between distribution transformations easy to compute. Later, with <strong>diffusion models</strong>, we’ll relax the architecture constraints a little bit so that the network will no longer be invertible, and we will only be able to train on an approximation of the likelihood. But these relaxations allow for some much more expressive models and better sample quality.</p>
<p>Normalizing flows are called as such because they transform a probability distribution through a sequence of mappings of the same dimensionality (thus it flows), and the inverse mappings transform a complex data distribution into a normalized one, often the normal distribution (thus it normalizes). As we can see, diffusion models also roughly share the same concepts. Recent SOTA generative models are often a mixture of the two.</p>
<p>The <strong>general model structure</strong> goes as follows. We start with a latent variable <span class="math inline">\(\mathbf{z}\)</span>, distributed according to a simple distribution <span class="math inline">\(p_{\mathbf{z}}(\mathbf{z})\)</span>, a function <span class="math inline">\(\mathbf{x} = f(\mathbf{z}, \mathbf{w})\)</span> parameterized by a neural network that transforms the latent space into the data space, and its inverse function <span class="math inline">\(\mathbf{z} = g(\mathbf{x}, \mathbf{w})= g(f(\mathbf{z}, \mathbf{w}), \mathbf{w})\)</span> that transforms the data space back into the latent space. The data likelihood is then given by the change of variables formula:</p>
<p><span class="math display">\[
p_{\mathbf{x}}(\mathbf{x}|\mathbf{w}) = p_{\mathbf{z}}(g(\mathbf{x}, \mathbf{w})) \cdot |\det J(\mathbf{x})|
\]</span></p>
<p>where <span class="math inline">\(J(\mathbf{x})\)</span> is the Jacobian matrix of partial derivatives whose elements are given by:</p>
<p><span class="math display">\[
J_{ij}(\mathbf{x}) = \frac{\partial g_i(\mathbf{x}, \mathbf{w})}{\partial x_j}.
\]</span></p>
<p>To make sure that transformation is invertible, function <span class="math inline">\(f\)</span> has to be a one-to-one mapping, this adds some constraints on the architecture of the neural network. Also computing the determinant of the Jacobian matrix can be computationally expensive, so we might impose some further restrictions on the network structure to make it more efficient.</p>
<p>If we consider a training set <span class="math inline">\(\mathcal{D} = \{\mathbf{x}_1, \ldots, \mathbf{x}_N\}\)</span> of independent data points, the <strong>log likelihood function</strong></p>
<p><span class="math display">\[
\ln p(\mathcal{D}|\mathbf{w}) = \sum_{n=1}^N \ln p_{\mathbf{x}}(\mathbf{x}_n|\mathbf{w}) = \sum_{n=1}^N \left[ \ln p_{\mathbf{z}}(g(\mathbf{x}_n, \mathbf{w})) + \ln |\det J(\mathbf{x}_n)| \right]
\]</span></p>
<p>will serve as the objective function to train the neural network. The first term is the log likelihood of the latent variable, the second term is the log determinant of the Jacobian matrix.</p>
<p>To be able to model a wide range of distributions, we want the transformation function <span class="math inline">\(\mathbf{x} = f(\mathbf{z}, \mathbf{w})\)</span> to be highly flexible, so we use a deep neural network with multiple layers. We can ensure that the overall function is invertible if we make each layer of the network invertible. And the two terms in the data likelihood, the latent variable likelihood and the Jacobian determinant, can both be computed easily under such a layered structure, using the chain rule of calculus.</p>
<section id="coupling-flows" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="coupling-flows"><span class="header-section-number">3.1</span> coupling flows</h2>
<p>Recall that in flow models we aim for <strong>the following goals</strong>:</p>
<ol type="1">
<li>The transformation function <span class="math inline">\(f\)</span> should be (easily enough) invertible, so that we can compute the latent variable likelihood.</li>
<li>The Jacobian determinant of the transformation should be easy to compute, so that we can correct the latent likelihood to get the data likelihood.</li>
<li>We should be able to sample from it. Once the above two are met, this is usually straightforward, although the computation cost might vary.</li>
</ol>
<p>Each flow model will attempt to meet these goals in different ways. In <strong>coupling flows</strong>, for each layer of the network, we first split the latent variable <span class="math inline">\(\mathbf{z}\)</span> into two parts <span class="math inline">\(\mathbf{z} = (\mathbf{z}_A, \mathbf{z}_B)\)</span>, then apply the following transformation:</p>
<p><span class="math display">\[
\begin{align}
\mathbf{X}_A &amp;= \mathbf{Z}_A, \\
\mathbf{X}_B &amp;= \exp(s(\mathbf{Z}_A, w)) \odot \mathbf{Z}_B + b(\mathbf{Z}_A, w).
\end{align}
\]</span></p>
<p>The frist part <span class="math inline">\(\mathbf{X}_A\)</span> is simply left unchanged, and all the efforts are put into transforming the second part <span class="math inline">\(\mathbf{X}_B\)</span>. The transformation is done by a neural network with parameters <span class="math inline">\(w\)</span>, which takes <span class="math inline">\(\mathbf{Z}_A\)</span> as input and outputs two vectors <span class="math inline">\(s(\mathbf{Z}_A, w)\)</span> and <span class="math inline">\(b(\mathbf{Z}_A, w)\)</span> of the same dimensionality as <span class="math inline">\(\mathbf{Z}_B\)</span>. Besides, an <span class="math inline">\(\exp\)</span> function is used to ensure that the Jacobian determinant is easy to compute.</p>
<p><img src="./img/DLFC/Chapter-18/Figure_1.png" class="img-fluid"></p>
<p>Now let’s check how this formula meets the three aformentioned goals. <strong>First</strong> is invertability. Simply rearrange the terms and we can get the inverse transformation:</p>
<p><span class="math display">\[
\begin{align}
\mathbf{Z}_A &amp;= \mathbf{X}_A, \\
\mathbf{Z}_B &amp;= (\mathbf{X}_B - b(\mathbf{X}_A, w)) \odot \exp(-s(\mathbf{X}_A, w)).
\end{align}
\]</span></p>
<p>Notice how the inverse transformation does not involve inverting the neural networks at all, just changing the sign of the <span class="math inline">\(\exp\)</span> function. This is the key to making the transformation invertible easy and efficient.</p>
<p><strong>Second</strong> is computing the Jacobian determinant. It turns out the Jacobian is a lower trianglular matrix</p>
<p><span class="math display">\[
\begin{bmatrix}
\mathbf{I} &amp; 0 \\
\frac{\partial \mathbf{Z}_B}{\partial \mathbf{X}_A} &amp; \text{diag}(-\exp(s(\mathbf{Z}_A, w)))
\end{bmatrix}
\]</span></p>
<p>and the determinant is simply the product of the diagonal elements.</p>
<ol type="1">
<li><span class="math inline">\(\mathbf{Z}_A\)</span> is an identity transformation of <span class="math inline">\(\mathbf{X}_A\)</span>, so <span class="math inline">\(\frac{\partial \mathbf{Z}_A}{\partial \mathbf{X}_A}\)</span> is an identity matrix.</li>
<li><span class="math inline">\(\frac{\partial \mathbf{Z}_A}{\partial \mathbf{X}_B}\)</span> is zero.</li>
<li><span class="math inline">\(\mathbf{Z}_B\)</span> is <span class="math inline">\(\mathbf{X}_B\)</span> minus a linear transformation of <span class="math inline">\(\mathbf{X}_A\)</span> (doesn’t involve <span class="math inline">\(\mathbf{Z}_B\)</span>), then element-wise multiplied by the exponential term (meaning no interaction among <span class="math inline">\(\mathbf{Z}_B\)</span>), so <span class="math inline">\(\frac{\partial \mathbf{Z}_B}{\partial \mathbf{X}_B}\)</span> is a diagonal matrix, and the diagonal values are the corresponding negatives of the exponential term. Up to this point we know the Jacobian matrix itselve is a lower triangular matrix.</li>
<li><span class="math inline">\(\frac{\partial \mathbf{Z}_B}{\partial \mathbf{X}_A}\)</span> is more complicated, but it doesn’t factor into the Jacobian determinant so can be safely ignored.</li>
</ol>
<p>To make the network more expressive, normalizing flows often have multiple coupling layers stacked together, switching the roles of <span class="math inline">\(\mathbf{Z}_A\)</span> and <span class="math inline">\(\mathbf{Z}_B\)</span> at each layer, and possibly also changing the split points at each layer. The final data likelihood is the product of the likelihoods at each layer. And the Jacobian determinant is the product of the determinants at each layer.</p>
<p><img src="./img/DLFC/Chapter-18/Figure_2.png" class="img-fluid"></p>
<p><strong>Third</strong> is sampling. Once the model is trained, we can start with <span class="math inline">\(\mathbf{Z}_A\)</span>, and follow the flow till we get to <span class="math inline">\(\mathbf{X}\)</span>. The sampling process is deterministic and easy to compute.</p>
<p>As an example we can train a normalizing flow model on a two-moons dataset, using the <code>normflows</code> package. The following code is adapted from the package’s example code.</p>
<div id="e85c2d5d" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import required packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> normflows <span class="im">as</span> nf</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is the target distribution</p>
<div id="38d1c196" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define target distribution</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> nf.distributions.TwoMoons()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot target distribution</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>grid_size <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> torch.meshgrid(torch.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, grid_size), torch.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, grid_size), indexing<span class="op">=</span><span class="st">'xy'</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>zz <span class="op">=</span> torch.cat([xx.unsqueeze(<span class="dv">2</span>), yy.unsqueeze(<span class="dv">2</span>)], <span class="dv">2</span>).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>zz <span class="op">=</span> zz.to(device)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>log_prob <span class="op">=</span> target.log_prob(zz).to(<span class="st">'cpu'</span>).view(<span class="op">*</span>xx.shape)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>prob <span class="op">=</span> torch.exp(log_prob)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>prob[torch.isnan(prob)] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>plt.pcolormesh(xx, yy, prob.data.numpy(), cmap<span class="op">=</span><span class="st">'hot'</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>plt.gca().set_aspect(<span class="st">'equal'</span>, <span class="st">'box'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="18_files/figure-html/cell-3-output-1.png" width="421" height="415" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Construct the model. To define a normalizing flow model, we first specify the base distribution and the transformation layers, and then combine them in the <code>NormalizingFlow</code> class.</p>
<div id="b130ed87" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define 2D Gaussian base distribution</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>base <span class="op">=</span> nf.distributions.base.DiagGaussian(<span class="dv">2</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define list of flows</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>num_layers <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>flows <span class="op">=</span> []</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_layers):</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Neural network with two hidden layers having 64 units each</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Last layer is initialized by zeros making training more stable</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    param_map <span class="op">=</span> nf.nets.MLP([<span class="dv">1</span>, <span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">2</span>], init_zeros<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add flow layer</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    flows.append(nf.flows.AffineCouplingBlock(param_map))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Swap dimensions</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    flows.append(nf.flows.Permute(<span class="dv">2</span>, mode<span class="op">=</span><span class="st">'swap'</span>))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nf.NormalizingFlow(base, flows)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Train the model.</p>
<div id="2379d11c" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>max_iter <span class="op">=</span> <span class="dv">3201</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>num_samples <span class="op">=</span> <span class="dv">2</span> <span class="op">**</span> <span class="dv">9</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>show_iter <span class="op">=</span> <span class="dv">800</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>loss_hist <span class="op">=</span> np.array([])</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>prob_list <span class="op">=</span> []</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">5e-4</span>, weight_decay<span class="op">=</span><span class="fl">1e-5</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> it <span class="kw">in</span> tqdm(<span class="bu">range</span>(max_iter)):</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get training samples</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> target.sample(num_samples).to(device)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute loss</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> model.forward_kld(x)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Do backprop and optimizer step</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">~</span>(torch.isnan(loss) <span class="op">|</span> torch.isinf(loss)):</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log loss</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    loss_hist <span class="op">=</span> np.append(loss_hist, loss.to(<span class="st">'cpu'</span>).data.numpy())</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save prob for later plotting</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> it <span class="op">%</span> show_iter <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        log_prob <span class="op">=</span> model.log_prob(zz)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        prob <span class="op">=</span> torch.exp(log_prob.to(<span class="st">'cpu'</span>).view(<span class="op">*</span>xx.shape))</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        prob[torch.isnan(prob)] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        prob_list.append(prob.data.numpy())</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>plt.plot(loss_hist)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|          | 0/3201 [00:00&lt;?, ?it/s]  0%|          | 15/3201 [00:00&lt;00:21, 149.57it/s]  2%|▏         | 64/3201 [00:00&lt;00:09, 348.03it/s]  3%|▎         | 111/3201 [00:00&lt;00:07, 400.08it/s]  5%|▍         | 157/3201 [00:00&lt;00:07, 420.78it/s]  6%|▋         | 202/3201 [00:00&lt;00:06, 430.97it/s]  8%|▊         | 248/3201 [00:00&lt;00:06, 438.31it/s]  9%|▉         | 294/3201 [00:00&lt;00:06, 442.53it/s] 11%|█         | 339/3201 [00:00&lt;00:06, 444.55it/s] 12%|█▏        | 384/3201 [00:00&lt;00:06, 446.14it/s] 13%|█▎        | 430/3201 [00:01&lt;00:06, 448.35it/s] 15%|█▍        | 475/3201 [00:01&lt;00:06, 448.17it/s] 16%|█▌        | 520/3201 [00:01&lt;00:05, 447.81it/s] 18%|█▊        | 566/3201 [00:01&lt;00:05, 448.81it/s] 19%|█▉        | 611/3201 [00:01&lt;00:05, 445.47it/s] 20%|██        | 656/3201 [00:01&lt;00:05, 446.51it/s] 22%|██▏       | 701/3201 [00:01&lt;00:05, 446.64it/s] 23%|██▎       | 746/3201 [00:01&lt;00:05, 446.91it/s] 25%|██▍       | 791/3201 [00:01&lt;00:05, 447.78it/s] 26%|██▌       | 836/3201 [00:01&lt;00:05, 438.08it/s] 28%|██▊       | 881/3201 [00:02&lt;00:05, 441.20it/s] 29%|██▉       | 926/3201 [00:02&lt;00:05, 441.27it/s] 30%|███       | 971/3201 [00:02&lt;00:05, 442.14it/s] 32%|███▏      | 1017/3201 [00:02&lt;00:04, 444.51it/s] 33%|███▎      | 1062/3201 [00:02&lt;00:04, 444.95it/s] 35%|███▍      | 1107/3201 [00:02&lt;00:04, 446.39it/s] 36%|███▌      | 1152/3201 [00:02&lt;00:04, 446.95it/s] 37%|███▋      | 1197/3201 [00:02&lt;00:04, 443.93it/s] 39%|███▉      | 1242/3201 [00:02&lt;00:04, 445.48it/s] 40%|████      | 1287/3201 [00:02&lt;00:04, 445.54it/s] 42%|████▏     | 1332/3201 [00:03&lt;00:04, 446.29it/s] 43%|████▎     | 1377/3201 [00:03&lt;00:04, 445.23it/s] 44%|████▍     | 1422/3201 [00:03&lt;00:04, 444.74it/s] 46%|████▌     | 1467/3201 [00:03&lt;00:03, 446.30it/s] 47%|████▋     | 1512/3201 [00:03&lt;00:03, 446.52it/s] 49%|████▊     | 1557/3201 [00:03&lt;00:03, 446.73it/s] 50%|█████     | 1602/3201 [00:03&lt;00:03, 444.11it/s] 51%|█████▏    | 1647/3201 [00:03&lt;00:03, 441.48it/s] 53%|█████▎    | 1692/3201 [00:03&lt;00:03, 443.78it/s] 54%|█████▍    | 1737/3201 [00:03&lt;00:03, 445.33it/s] 56%|█████▌    | 1782/3201 [00:04&lt;00:03, 445.83it/s] 57%|█████▋    | 1828/3201 [00:04&lt;00:03, 447.55it/s] 59%|█████▊    | 1873/3201 [00:04&lt;00:02, 447.12it/s] 60%|█████▉    | 1918/3201 [00:04&lt;00:02, 447.26it/s] 61%|██████▏   | 1963/3201 [00:04&lt;00:02, 447.33it/s] 63%|██████▎   | 2008/3201 [00:04&lt;00:02, 447.37it/s] 64%|██████▍   | 2053/3201 [00:04&lt;00:02, 447.26it/s] 66%|██████▌   | 2098/3201 [00:04&lt;00:02, 447.30it/s] 67%|██████▋   | 2143/3201 [00:04&lt;00:02, 447.96it/s] 68%|██████▊   | 2188/3201 [00:04&lt;00:02, 448.04it/s] 70%|██████▉   | 2234/3201 [00:05&lt;00:02, 448.40it/s] 71%|███████   | 2279/3201 [00:05&lt;00:02, 447.09it/s] 73%|███████▎  | 2324/3201 [00:05&lt;00:01, 446.44it/s] 74%|███████▍  | 2370/3201 [00:05&lt;00:01, 447.81it/s] 75%|███████▌  | 2415/3201 [00:05&lt;00:01, 444.66it/s] 77%|███████▋  | 2461/3201 [00:05&lt;00:01, 447.19it/s] 78%|███████▊  | 2506/3201 [00:05&lt;00:01, 445.27it/s] 80%|███████▉  | 2551/3201 [00:05&lt;00:01, 445.60it/s] 81%|████████  | 2596/3201 [00:05&lt;00:01, 446.04it/s] 83%|████████▎ | 2642/3201 [00:05&lt;00:01, 446.93it/s] 84%|████████▍ | 2687/3201 [00:06&lt;00:01, 444.15it/s] 85%|████████▌ | 2732/3201 [00:06&lt;00:01, 444.66it/s] 87%|████████▋ | 2777/3201 [00:06&lt;00:00, 445.03it/s] 88%|████████▊ | 2822/3201 [00:06&lt;00:00, 445.70it/s] 90%|████████▉ | 2867/3201 [00:06&lt;00:00, 446.12it/s] 91%|█████████ | 2912/3201 [00:06&lt;00:00, 446.45it/s] 92%|█████████▏| 2957/3201 [00:06&lt;00:00, 440.97it/s] 94%|█████████▍| 3002/3201 [00:06&lt;00:00, 442.14it/s] 95%|█████████▌| 3047/3201 [00:06&lt;00:00, 442.77it/s] 97%|█████████▋| 3092/3201 [00:06&lt;00:00, 444.39it/s] 98%|█████████▊| 3137/3201 [00:07&lt;00:00, 445.22it/s] 99%|█████████▉| 3182/3201 [00:07&lt;00:00, 445.20it/s]100%|██████████| 3201/3201 [00:07&lt;00:00, 442.53it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="18_files/figure-html/cell-5-output-2.png" width="571" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Plot the results. We can see that the model has (roughly) learned the distribution of the two moons dataset.</p>
<div id="7e15b4bb" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="bu">len</span>(prob_list), figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">2</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, prob <span class="kw">in</span> <span class="bu">enumerate</span>(prob_list):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[i]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    c <span class="op">=</span> ax.pcolormesh(xx, yy, prob, cmap<span class="op">=</span><span class="st">'hot'</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    ax.set_aspect(<span class="st">'equal'</span>, <span class="st">'box'</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust the colorbar to have more padding</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>cbar <span class="op">=</span> fig.colorbar(c, ax<span class="op">=</span>axes, orientation<span class="op">=</span><span class="st">'vertical'</span>, fraction<span class="op">=</span><span class="fl">0.02</span>, pad<span class="op">=</span><span class="fl">0.02</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="18_files/figure-html/cell-6-output-1.png" width="815" height="177" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="autoregressive-flows" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="autoregressive-flows"><span class="header-section-number">3.2</span> autoregressive flows</h2>
<p><img src="./img/DLFC/Chapter-18/Figure_4_a.png" class="img-fluid"></p>
<p><img src="./img/DLFC/Chapter-18/Figure_4_b.png" class="img-fluid"></p>
</section>
<section id="continuous-flows" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="continuous-flows"><span class="header-section-number">3.3</span> continuous flows</h2>
<p>In normalizing flow models, for each transformation layer, the input and output always have the same dimensionality, we are thus looking for a more meaningful representation of the same data space. There is another neural network sharing this property, namely residual networks, but there is no guarantee that such a network will be invertible. Here we introduce a well known mathematical concept, the differential equation, into the neural network, and thus satisfying both the invertibility and the constant dimensionality requirements.</p>
<section id="neural-differential-equation" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="neural-differential-equation"><span class="header-section-number">3.3.1</span> neural differential equation</h3>
<p>Neural differential equation, as the name implies, is a neural network that is defined by a differential equation. We can consider the residual network as a discrete version of the differential equation, since the “residual” is already a difference between consecutive layers, and the differential is the limit of this difference as it approaches zero. Thus starting from a residual network</p>
<p><span class="math display">\[
\mathbf{z}_{t+1} = \mathbf{z}_t + f(\mathbf{z}_t, \mathbf{w})
\]</span></p>
<p>we can readily convert it into a differential equation</p>
<p><span class="math display">\[
\frac{d\mathbf{z(t)}}{dt} = f(\mathbf{z(t)}, \mathbf{w}).
\]</span></p>
<p>Now defining something is easy, what really matters is what we can do with it. On the modeling side, starting from an initial state <span class="math inline">\(\mathbf{z}_0\)</span>, we no longer need to define the number of layers in the network. we can integrate the differential equation to get the state at any time <span class="math inline">\(t\)</span>,</p>
<p><img src="./img/DLFC/Chapter-18/Figure_5.png" class="img-fluid"></p>
</section>
<section id="neural-ode-backpropagation" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="neural-ode-backpropagation"><span class="header-section-number">3.3.2</span> neural ODE backpropagation</h3>
</section>
<section id="neural-ode-flows" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="neural-ode-flows"><span class="header-section-number">3.3.3</span> neural ODE flows</h3>
<p><img src="./img/DLFC/Chapter-18/Figure_6_a.png" class="img-fluid"></p>
<p><img src="./img/DLFC/Chapter-18/Figure_6_b.png" class="img-fluid"></p>
<p><img src="./img/DLFC/Chapter-18/Figure_6_c.png" class="img-fluid"></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./07.html" class="pagination-link" aria-label="Gradient Descent">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Gradient Descent</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./20.html" class="pagination-link" aria-label="Diffusion Models">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Diffusion Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>